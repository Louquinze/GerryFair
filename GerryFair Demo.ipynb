{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GerryFair Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Data Format\n",
    "\n",
    "To test on a custom dataset, two files are needed: a file for the dataset itself and a file listing the types of attributes in the dataset. The dataset itself only needs the label column to have\n",
    "values in 0,1. Our cleaning will automatically one-hot encode the categorical variables and, if desired, center the data.\n",
    "\n",
    "For the attributes, each column should have a corresponding label, 0 (unprotected attribute), 1 (protected attribute), or 2 (label). See *communities_protected_formatted.csv* for an example.\n",
    "\n",
    "#### Cleaning Data\n",
    "If your data is not in that format, it needs to be cleaned. We provide a method, `clean_data` in *clean.py*, you can use to clean your data into the accepted format. \n",
    "\n",
    "The variable `dataset` should hold the file path to the file containing the dataset. The variable `attributes` should hold the file path to the file containing protected attributes. You should set `centered` to be `True` if you want the data to be centered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"./dataset/communities.csv\"\n",
    "attributes = \"./dataset/communities_protected.csv\"\n",
    "centered = True\n",
    "X, X_prime, y = clean_dataset(dataset, attributes, centered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Clean Data\n",
    "\n",
    "If you have already cleaned the data or have the data already in the required form, we provide a tool to load in the relevant data. The two files should be in XXX form..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"communities\"\n",
    "X, X_prime, y = clean.get_data(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using tools to train a model\n",
    "\n",
    "Once the data is cleaned, we can use the ficticious play algorithm. This can be done using the `fictitious_play` function we provide. It requires to be passed in `X`, `X_prime`, and `y` and has a variety of optionsfor output and specifications for running, including an option to print heatmaps and change the number of iterations of the algorithm. Here, we will train a model on the communities data, printing heatmaps and setting the number of iterations to be 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 15\n",
    "printflag = True\n",
    "heatmapflag = True\n",
    "heatmap_iter = 2\n",
    "max_iter = 15\n",
    "gamma = .01\n",
    "errors_t, fp_diff_t = fictitious_play(X, X_prime, y, C, printflag, heatmapflag, heatmap_iter, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using tools on evaluate a generic model\n",
    "\n",
    "Once we have a model, whether it is fictitious play model or any generic model, we can use our tools to evaluate the fairness in several ways.\n",
    "\n",
    "#### Auditing Predictions\n",
    "\n",
    "You can audit for subgroup fairness of your predictions using the `audit` functionality. These predictions can come from any arbitrary model. Auditing the predictions returns the gamma unfairness of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ...\n",
    "gamma_unfairness = audit(predictions, X, X_prime, y,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting errors\n",
    "You can also plot the errors of the model during training using the `plot_single` function in *fairness_plots.py*. Please note that these errors are returned by our fictitious play algorithm, so this is specifically for analyzing the effectiveness of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_plots.plot_single(errors_t, fp_diff_t, max_iters, gamma, C)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
